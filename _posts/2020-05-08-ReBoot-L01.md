---
title: RSS is Sub-Exponential
author: Murasashi
date: 2020-05-08 16:00:00 +0400
categories: [Research] 
tags: [reboot, sub-exponential]
---

## ReBoot Lecture 01

This post devotes to show sub-exponential tail of RSS.


## Point 1: Tail of RSS is flatter than tail of square sum process.

### Key Observation

Recall from the definition of Residual sum of square (RSS) that $\text{RSS}_{k,s} = \sum_{i=1}^{s}Y_{k,i}^2-s^{-1}(\bar{Y}_{k,s})^2$. The upper deviation event of $\text{RSS}_{k,s}$ beyond a constant level $t$ now has form 

$$\{\text{RSS}_{k,s} >t\} = \{\sum_{i=1}^{s}Y_{k,i}^2>t+s^{-1}(\bar{Y}_{k,s})^2\}\subset  \{\sum_{i=1}^{s}Y_{k,i}^2>t\},$$
where the inclusion is from the non-negativity of $s^{-1}(\bar{Y}_{k,s})^2$. Thus, we at least sure that

$$P(\{\text{RSS}_{k,s} >t\})\le P( \{\sum_{i=1}^{s}Y_{k,i}^2>t\}).$$

Thus, we shift our attention to the upper deviation event of __square sum process__ of __mean zero sub-Gaussian__ response $Y_{k,i}$.


## Point 2: Working on Orlicz quasi-norm

### Definition

The sub-Gaussian norm $\|X\|_{\psi_2}$ is defined as

$$\|X\|_{\psi_2} \equiv \inf\{t >0: E[\exp(X^2/t^2)]\le 2\}.$$

The sub-exponential norm $\|X\|_{\psi_1}$ is defined as

$$\|X\|_{\psi_1} \equiv \inf\{t >0: E[\exp(|X|/t)]\le 2\}.$$




### Example

Take normal reward case $Y=N(\mu,\sigma^2)$. Elementary statistics shows the normalization $(Y-\mu)/\sigma$ has degree 1 chi-square distribution $\chi_1^2$. Recall that the moment generating function of $\chi^2_1$ is $M_{\chi^2_1}(\lambda)=(1-2\lambda)^{-1/2}I(\lambda < 1/2)$ and picking $\lambda = 3/8$ gives $M_{\chi^2_1}(3/8)=2$. Thus, one has 

$$\|Y-\mu\|_{\psi_2} \le 2\sqrt{2/3} \sigma$$

and also

$$\|(Y-\mu)^2\|_{\psi_1} \le (8/3)\sigma^2.$$

Therefore, for normal reward $Y\sim N(\mu, \sigma^2)$, the deviation $Y-\mu$ is sub-exponential distributed of sub-exponential norm $(8/3)\sigma^2$. (It's interesting that we need factor (8/3), which suggests necessary __uncertainty boosting__ should be designed when using sub-exponential based analysis.

> P.24 includes examples of Gaussian, Bernoulli and Bounded distribution. 

> Remark: in HDS, Example 2.11(P.29), $\chi_1^2$ is of sub-exponential $(\nu, \alpha)=(2\sqrt{n}, 4)$, due to an approximation in Example 2.8 (P. 26).  Then see (2.18) at page 29 for deviation inequality of __sample average__ of sub-exponential process.

Then we can use __sub-exponential concentration__

$$P((Y-\mu)^2>t)\le 2\exp(-t/\|(Y-\mu)^2\|_{\psi_1}).$$

## Point 3: Deviation of Sub-exponential Sum process

The goal of this point is to think through page 29 of HDS for deviation inequality of __sample average__ of sub-exponential process.

### Sub-exponential distribution

We write $X_k\sim \text{subEXP}(\mu_k, \alpha_k)$ if its moment generating function is locally bounded by a quadratic function around $0$; formally, 

$$M_{X_k}(\lambda) \le v_{k}^2 (\lambda^2/2)\text{ for all } |\lambda| \le \alpha_k^{-1}.$$

### Targeted Example

Given a sub-Gaussian reward $Y_k$ with mean $\mu$ and variance $\sigma^2$, we concern the upper deviation event of the __average square deviation process__ $t^{-1}\sum_{s=1}^{t}(Y_{s}-\mu)^2$. Note that the square deviation $(Y_s-\mu)^2$ is centered at the $\sigma^2$ (of what parameter $\alpha_{s}$???). Then, we have deviation inequality from (2.18) at HDS, page 29 that, for __any $t \ge \sigma^2$__

$$P(t^{-1}\sum_{s=1}^{n}(Y_{s}-\mu)^2-\sigma^2 \ge t) \le \exp(-(nt/2\alpha)).$$

The version of interests is for any $t\ge n\sigma^2$, we have 

$$P(\sum_{s=1}^{n}(Y_{s}-\mu)^2-n\sigma^2 \ge t) \le \exp(-t/2\alpha).$$

The question remaining is what $\alpha$ is for a sub-Gaussian variable. This question could be answered after pondering the Proposition 2.7.1 at P.29 of HDP. 

## Point 4:


## Point 5:


## Point 6:


## Conclusion


